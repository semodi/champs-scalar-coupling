{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/miniconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['connect']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ase.io import read, write\n",
    "from ase.visualize import view\n",
    "from ase.io import read\n",
    "from ase.db import connect\n",
    "import dask\n",
    "import dask.threaded\n",
    "\n",
    "from ase.calculators.singlepoint import SinglePointCalculator\n",
    "%pylab inline\n",
    "from ase.db import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_molecules = pd.read_csv('./data/structures.csv').groupby('molecule_name').groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed    \n",
    "def add_data(idx, args):\n",
    "    try:\n",
    "        molecule_name, idx0, idx1, coupling = args\n",
    "    except ValueError:\n",
    "        molecule_name, idx0, idx1 = args\n",
    "        coupling = 0\n",
    "        \n",
    "    path = 'data/structures/' + molecule_name  + '.xyz'\n",
    "    atoms = read(path)\n",
    "    atom_mask = np.zeros(len(atoms.positions))\n",
    "    atom_mask[idx0] = 1\n",
    "    atom_mask[idx1] = 1\n",
    "    entry = dict(atoms = atoms, _atom_mask = atom_mask, coupling = coupling, champs_id = idx)\n",
    "    \n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/test.csv')\n",
    "\n",
    "for d,el in [(1,'N'),(2, 'N'),(3, 'N'),(1,'C'),(2,'C'),(3,'C'),(2,'H'),(3,'H')]:\n",
    "    type_sel = train[train['type']=='{}JH{}'.format(d,el)].set_index('id',drop=True).drop(['type'],axis=1)\n",
    "\n",
    "    step_size = int(np.ceil(len(type_sel)/100))\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        futures = [add_data(idx, args) for idx, args in  type_sel.iloc[i*step_size:(i+1)*step_size].iterrows()]\n",
    "\n",
    "        results = dask.compute(*futures, scheduler='threads')\n",
    "\n",
    "        with connect('data/jh{}_{}.db'.format(el.lower(),d)) as db:\n",
    "            for idx, entry in enumerate(results):\n",
    "                mask = entry.pop('_atom_mask')\n",
    "                db.write(**entry, data ={'_atom_mask': mask})\n",
    "        del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lgbm_train_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhn1 = train[train['type'] == '1JHN']\n",
    "\n",
    "total_len = len(jhn1)\n",
    "\n",
    "jhn1['diff'] = jhn1['scalar_coupling_constant'] - jhn1['scalar_coupling_constant_predicted']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ids = []\n",
    "coupling = []\n",
    "for idx, (item, (_, row)) in enumerate(zip(db.select(),jhn1.iterrows())):\n",
    "    if idx%int(total_len/100) == 0:\n",
    "        print('{} %'.format(int(idx/(total_len/100) )))\n",
    "    \n",
    "    coupling.append(row['diff'])\n",
    "    ids.append(item.id)\n",
    "    if idx%100 == 0:\n",
    "        with connect('data/training/jhn_1_lgbm.db') as db:\n",
    "            for i, c in zip(ids,coupling):\n",
    "#                 print(i,c)\n",
    "                db.update(i, coupling_min_lgbm = c)\n",
    "        coupling = []\n",
    "        ids = []\n",
    "        \n",
    "with connect('data/training/jhn_1.db') as db:\n",
    "    for i, c in zip(ids,coupling):\n",
    "    #                 print(i,c)\n",
    "        db.update(i, coupling_min_lgbm = c)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with connect('data/training/jhn_1_lgbm.db') as db:\n",
    "    for i, c in zip(ids,coupling):\n",
    "    #                 print(i,c)\n",
    "        db.update(i, coupling_min_lgbm = c)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.ida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = jhn1.iterrows().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.002361291503909513"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['scalar_coupling_constant'] - b['scalar_coupling_constant_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
